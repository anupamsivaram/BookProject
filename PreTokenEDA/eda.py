# -*- coding: utf-8 -*-
"""EDA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DJ6LT6sIUi9zkAbdDOE062B4EPcIu6M3
"""

import pandas as pd

# Load the updated CSV file with one-hot encoded genres
goodreads = pd.read_csv('goodreads_data_with_genres.csv')

# Find columns representing genres by excluding non-genre columns
genre_columns = goodreads.columns[goodreads.columns.str.contains('Genres|Avg_Rating|Num_Ratings|URL|Book|Author|Description', regex=True) == False]

# Count of unique genres
num_genres = len(genre_columns)
print(f"Number of unique genres: {num_genres}")

# Calculate frequency of each genre
genre_counts = goodreads[genre_columns].sum().sort_values(ascending=False)

# Display top 10 most common genres
top_10_genres = genre_counts.head(10)
print("Top 10 Most Common Genres:")
print(top_10_genres)

# Display bottom 10 least common genres
bottom_10_genres = genre_counts.tail(10)
print("\nBottom 10 Least Common Genres:")
print(bottom_10_genres)

# Filter dataset for titles with 'Nonfiction' tag
nonfiction_titles = goodreads[goodreads['Nonfiction'] == 1]

# Exclude 'Nonfiction' from genre columns
nonfiction_genre_counts = nonfiction_titles[genre_columns.difference(['Nonfiction'])].sum().sort_values(ascending=False)

# Top 10 most common genres for 'Nonfiction' titles
top_10_nonfiction = nonfiction_genre_counts.head(10)
print("\nTop 10 Most Common Genres in Nonfiction Titles (Excluding 'Nonfiction'):")
print(top_10_nonfiction)

# Bottom 10 least common genres for 'Nonfiction' titles
bottom_10_nonfiction = nonfiction_genre_counts.tail(10)
print("\nBottom 10 Least Common Genres in Nonfiction Titles (Excluding 'Nonfiction'):")
print(bottom_10_nonfiction)

# Filter dataset for titles without 'Nonfiction' tag
fiction_titles = goodreads[goodreads['Nonfiction'] == 0]

# Frequency count of genres for fiction-only titles
fiction_genre_counts = fiction_titles[genre_columns].sum().sort_values(ascending=False)

# Top 10 most common genres for fiction titles
top_10_fiction = fiction_genre_counts.head(10)
print("\nTop 10 Most Common Genres in Fiction Titles:")
print(top_10_fiction)

# Bottom 10 least common genres for fiction titles
bottom_10_fiction = fiction_genre_counts.tail(10)
print("\nBottom 10 Least Common Genres in Fiction Titles:")
print(bottom_10_fiction)

# Identify only genre columns by excluding non-genre columns
genre_columns = genre_columns.difference(['Unnamed: 0', 'Fiction'])

# Filter dataset for titles with the 'Fiction' tag
fiction_titles = goodreads[goodreads['Fiction'] == 1]

# Count occurrences of other genres among fiction titles, excluding 'Fiction' and non-genre columns
fiction_genre_counts = fiction_titles[genre_columns].sum().sort_values(ascending=False)

# Select the top 15 genres associated with 'Fiction' titles
top_fiction_genres = fiction_genre_counts.head(15)

# Plotting the frequencies
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 6))
top_fiction_genres.plot(kind='bar')
plt.title("Top Genres Associated with 'Fiction' Titles")
plt.xlabel("Genre")
plt.ylabel("Frequency")
plt.xticks(rotation=45, ha="right")
plt.show()

# Select the top 20 genres associated with 'Fiction' titles
top_20_fiction_genres = fiction_genre_counts.head(20)

# Plotting the frequencies
plt.figure(figsize=(12, 8))
top_20_fiction_genres.plot(kind='bar')
plt.title("Top 20 Genres Associated with 'Fiction' Titles")
plt.xlabel("Genre")
plt.ylabel("Frequency")
plt.xticks(rotation=45, ha="right")
plt.show()

# Define the top 20 genres, excluding "Audiobook" and "Mystery Thriller"
top_20_genres = ['Fantasy', 'Classics', 'Historical Fiction', 'Young Adult', 'Mystery',
                 'Novels', 'Contemporary', 'Romance', 'Literature', 'Thriller',
                 'Science Fiction', 'Historical', 'Adventure', 'Crime', 'Childrens',
                 'Adult', 'Suspense', 'Horror']

# Filter dataset for titles that have at least one of these top 20 genres
filtered_titles = goodreads[goodreads[top_20_genres].sum(axis=1) > 0]

# Generate covariance matrix for these selected genres
covariance_matrix = filtered_titles[top_20_genres].cov()

# Display the covariance matrix
covariance_matrix

import seaborn as sns
import matplotlib.pyplot as plt

# Set the plot size and style
plt.figure(figsize=(12, 10))
sns.set(style="white")

# Generate a heatmap for the covariance matrix
sns.heatmap(covariance_matrix, annot=True, fmt=".2f", cmap="coolwarm", square=True, cbar_kws={"shrink": .8})

# Title and labels
plt.title("Covariance Heatmap of Top 20 Genres (Excluding 'Audiobook' and 'Mystery Thriller')")
plt.show()

# Generate a correlation matrix for the filtered genres
correlation_matrix = filtered_titles[top_20_genres].corr()

# Plotting the correlation heatmap
plt.figure(figsize=(12, 10))
sns.heatmap(correlation_matrix, annot=True, fmt=".2f", cmap="coolwarm", square=True, cbar_kws={"shrink": .8})
plt.title("Correlation Heatmap of Top 20 Genres (Excluding 'Audiobook' and 'Mystery Thriller')")
plt.show()

# Define the top 20 genres to consider, excluding "Audiobook" and "Mystery Thriller"
top_20_genres = ['Fantasy', 'Classics', 'Historical Fiction', 'Young Adult', 'Mystery',
                 'Novels', 'Contemporary', 'Romance', 'Literature', 'Thriller',
                 'Science Fiction', 'Historical', 'Adventure', 'Crime', 'Childrens',
                 'Adult', 'Suspense', 'Horror']

# Filter dataset for titles that have at least one of these top 20 genres
filtered_titles = goodreads[goodreads[top_20_genres].sum(axis=1) > 0]

# Get the number of titles being considered
num_titles_considered = filtered_titles.shape[0]
print(f"Number of titles currently considered: {num_titles_considered}")

# Count the number of titles in the filtered list that have the "Nonfiction" tag
num_nonfiction_in_filtered = filtered_titles['Nonfiction'].sum()
print(f"Number of titles with 'Nonfiction' tag in the filtered list: {num_nonfiction_in_filtered}")

# Exclude titles with the "Nonfiction" tag from the filtered dataset
filtered_fiction_titles = filtered_titles[filtered_titles['Nonfiction'] == 0]

# Get the number of titles being considered after exclusion
num_titles_after_exclusion = filtered_fiction_titles.shape[0]
print(f"Number of titles considered after excluding 'Nonfiction': {num_titles_after_exclusion}")

# Define the top 18 genres to include in the correlation matrix
top_18_genres = ['Fantasy', 'Classics', 'Historical Fiction', 'Young Adult', 'Mystery',
                 'Novels', 'Contemporary', 'Romance', 'Literature', 'Thriller',
                 'Science Fiction', 'Historical', 'Adventure', 'Crime', 'Childrens',
                 'Adult', 'Suspense', 'Horror']

# Generate the correlation matrix for the selected genres
correlation_matrix_fiction = filtered_fiction_titles[top_18_genres].corr()

# Display the correlation matrix (optional)
correlation_matrix_fiction

# Filter dataset for titles with the "Fiction" tag
fiction_titles = goodreads[goodreads['Fiction'] == 1]

# List of genre columns excluding "Fiction"
genre_columns_excluding_fiction = genre_columns.difference(['Fiction'])

# Count the frequency of each genre in the filtered dataset
fiction_genre_counts = fiction_titles[genre_columns_excluding_fiction].sum().sort_values(ascending=False)

# Get the top 20 most represented genres (excluding "Fiction")
top_20_fiction_genres = fiction_genre_counts.head(20)
print("Top 20 Genres Represented in Fiction Titles (Excluding 'Fiction'):")
print(top_20_fiction_genres)



# Define the top 20 genres excluding 'Audiobook' and 'Mystery Thriller'
top_20_genres_excluding_audiobook_mysterythriller = [
    'Fantasy', 'Classics', 'Historical Fiction', 'Young Adult', 'Mystery',
    'Novels', 'Contemporary', 'Romance', 'Literature', 'Thriller',
    'Science Fiction', 'Historical', 'Adventure', 'Crime', 'Childrens',
    'Adult', 'Suspense', 'Horror'
]

# Filter for titles tagged with "Fiction" and at least one of the other top 18 genres
filtered_fiction_titles = goodreads[
    (goodreads['Fiction'] == 1) &
    (goodreads[top_20_genres_excluding_audiobook_mysterythriller].sum(axis=1) > 0)
]

# Count the number of titles we're now considering
num_titles_considered = filtered_fiction_titles.shape[0]
print(f"Number of titles considered: {num_titles_considered}")

# Generate the correlation matrix for the selected top 18 genres
correlation_matrix_fiction = filtered_fiction_titles[top_20_genres_excluding_audiobook_mysterythriller].corr()

# Plotting the correlation heatmap
import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(12, 10))
sns.heatmap(correlation_matrix_fiction, annot=True, fmt=".2f", cmap="coolwarm", square=True, cbar_kws={"shrink": .8})
plt.title("Correlation Heatmap of Top 20 Genres in 'Fiction' Titles (Excluding 'Audiobook' and 'Mystery Thriller')")
plt.show()

# Define the top 18 genres to include in the network graph, excluding 'Audiobook' and 'Mystery Thriller'
top_18_genres = [
    'Fantasy', 'Classics', 'Historical Fiction', 'Young Adult', 'Mystery',
    'Novels', 'Contemporary', 'Romance', 'Literature', 'Thriller',
    'Science Fiction', 'Historical', 'Adventure', 'Crime', 'Childrens',
    'Adult', 'Suspense', 'Horror'
]

# Filter for titles tagged as 'Fiction' and that have at least one of the top 18 genres
filtered_fiction_titles = goodreads[
    (goodreads['Fiction'] == 1) &
    (goodreads[top_18_genres].sum(axis=1) > 0)
]

# Check the number of titles we're working with after filtering
num_titles_considered = filtered_fiction_titles.shape[0]
print(f"Number of titles considered: {num_titles_considered}")

# Calculate the co-occurrence matrix by taking a dot product of the genre columns
co_occurrence_matrix = filtered_fiction_titles[top_18_genres].T.dot(filtered_fiction_titles[top_18_genres])

# Remove self-co-occurrences (diagonal elements)
for genre in top_18_genres:
    co_occurrence_matrix.loc[genre, genre] = 0

import networkx as nx
import matplotlib.pyplot as plt

# Create a graph from the co-occurrence matrix
G = nx.Graph()

# Add edges to the graph based on the co-occurrence strength
for genre1 in top_18_genres:
    for genre2 in top_18_genres:
        if co_occurrence_matrix.loc[genre1, genre2] > 0:
            # Add an edge with weight equal to the co-occurrence count
            G.add_edge(genre1, genre2, weight=co_occurrence_matrix.loc[genre1, genre2])

# Position nodes using the spring layout for better visualization
pos = nx.spring_layout(G, seed=42)

# Draw nodes with size based on the degree (number of connections) of each node
node_sizes = [1000 * nx.degree(G, node) for node in G]

# Draw edges with thickness based on weight (co-occurrence strength)
edges = nx.draw_networkx_edges(
    G, pos,
    edge_color=[G[u][v]['weight'] for u, v in G.edges()],
    width=[0.1 * G[u][v]['weight'] for u, v in G.edges()],
    edge_cmap=plt.cm.Blues
)

# Draw nodes and labels
nx.draw_networkx_nodes(G, pos, node_size=node_sizes, node_color="skyblue")
nx.draw_networkx_labels(G, pos, font_size=10, font_family="sans-serif")

# Colorbar for edge weights
plt.colorbar(edges, label="Co-occurrence Strength")
plt.title("Genre Co-occurrence Network in Fiction Titles")
plt.axis("off")  # Turn off axis for cleaner look
plt.show()

import pandas as pd
import networkx as nx
import matplotlib.pyplot as plt

# Define the 18 genres we’re considering
selected_genres = [
    'Fantasy', 'Classics', 'Historical Fiction', 'Young Adult', 'Mystery',
    'Novels', 'Contemporary', 'Romance', 'Literature', 'Thriller',
    'Science Fiction', 'Historical', 'Adventure', 'Crime', 'Childrens',
    'Adult', 'Suspense', 'Horror'
]

# Ensure we're working with the filtered dataset of 'Fiction' titles with these genres
filtered_fiction_titles = goodreads[
    (goodreads['Fiction'] == 1) &
    (goodreads[selected_genres].sum(axis=1) > 0)
]

# Calculate the co-occurrence matrix for the selected genres
co_occurrence_matrix = filtered_fiction_titles[selected_genres].T.dot(filtered_fiction_titles[selected_genres])

# Remove self-co-occurrences
for genre in selected_genres:
    co_occurrence_matrix.loc[genre, genre] = 0

# Create the graph
G = nx.Graph()

# Add edges with weights based on co-occurrence values
for genre1 in selected_genres:
    for genre2 in selected_genres:
        if co_occurrence_matrix.loc[genre1, genre2] > 0:
            # Add edge with weight (thickness based on co-occurrence strength)
            G.add_edge(genre1, genre2, weight=co_occurrence_matrix.loc[genre1, genre2])

# Set up the circular layout
pos = nx.circular_layout(G)

# Draw the nodes
plt.figure(figsize=(10, 10))
nx.draw_networkx_nodes(G, pos, node_size=800, node_color="skyblue")

# Draw edges with varying thickness based on co-occurrence strength
edges = nx.draw_networkx_edges(
    G, pos,
    width=[0.05 * G[u][v]['weight'] for u, v in G.edges()],
    edge_color=[G[u][v]['weight'] for u, v in G.edges()],
    edge_cmap=plt.cm.Blues
)

# Draw labels
nx.draw_networkx_labels(G, pos, font_size=10, font_family="sans-serif")

# Add a colorbar to show co-occurrence strength
plt.colorbar(edges, label="Co-occurrence Strength")
plt.title("Genre Co-occurrence Network in Fiction Titles (Circular Layout)")
plt.axis("off")  # Hide the axes
plt.show()

import seaborn as sns

# Set up a color palette for the nodes
palette = sns.color_palette("Paired", n_colors=len(selected_genres))
node_colors = {genre: palette[i] for i, genre in enumerate(selected_genres)}

# Create the graph
G = nx.Graph()

# Add edges with weights based on co-occurrence values, filtering for stronger connections
threshold = 100  # Set a threshold to include only significant connections
for genre1 in selected_genres:
    for genre2 in selected_genres:
        weight = co_occurrence_matrix.loc[genre1, genre2]
        if weight > threshold:
            G.add_edge(genre1, genre2, weight=weight)

# Circular layout for genres
pos = nx.circular_layout(G)

# Draw nodes with colors and sizes based on connectivity (degree)
node_sizes = [1000 + 5 * G.degree(node) for node in G]
node_colors_mapped = [node_colors[node] for node in G]

plt.figure(figsize=(12, 12))
nx.draw_networkx_nodes(G, pos, node_size=node_sizes, node_color=node_colors_mapped, edgecolors="black")

# Draw edges with varying thickness, transparency, and color intensity
edges = nx.draw_networkx_edges(
    G, pos,
    width=[0.05 * G[u][v]['weight'] for u, v in G.edges()],
    alpha=0.6,  # Set transparency to reduce clutter
    edge_color=[G[u][v]['weight'] for u, v in G.edges()],
    edge_cmap=plt.cm.viridis  # More colorful colormap
)

# Draw labels with larger font size for clarity
nx.draw_networkx_labels(G, pos, font_size=12, font_family="sans-serif")

# Colorbar for edge weights to show co-occurrence strength
plt.colorbar(edges, label="Co-occurrence Strength")
plt.title("Enhanced Genre Co-occurrence Network in Fiction Titles (Circular Layout)")
plt.axis("off")  # Hide axes
plt.show()

# Import the correct module for community detection
from community import community_louvain  # Ensure you have installed `python-louvain`
import matplotlib.pyplot as plt
import seaborn as sns
import networkx as nx

# Community detection to find clusters
partition = community_louvain.best_partition(G)

# Define a color map for clusters
unique_clusters = list(set(partition.values()))
num_clusters = len(unique_clusters)
cluster_palette = sns.color_palette("hsv", num_clusters)
cluster_colors = {genre: cluster_palette[partition[genre]] for genre in G.nodes}

# Set up circular layout with padding for labels
pos = nx.circular_layout(G)

plt.figure(figsize=(12, 12))

# Draw nodes with cluster-based colors
nx.draw_networkx_nodes(G, pos, node_size=node_sizes, node_color=[cluster_colors[node] for node in G], edgecolors="black")

# Draw edges with varying thickness and transparency to reduce clutter
edges = nx.draw_networkx_edges(
    G, pos,
    width=[0.05 * G[u][v]['weight'] for u, v in G.edges()],
    alpha=0.5,  # Increased transparency for a cleaner look
    edge_color=[G[u][v]['weight'] for u, v in G.edges()],
    edge_cmap=plt.cm.coolwarm  # Distinct colormap for edges
)

# Draw labels with padding adjustments
nx.draw_networkx_labels(G, pos, font_size=12, font_family="sans-serif", bbox=dict(facecolor="white", edgecolor='none', boxstyle="round,pad=0.3"))

# Colorbar for edge weights to show co-occurrence strength
plt.colorbar(edges, label="Co-occurrence Strength")
plt.title("Clustered Genre Co-occurrence Network in Fiction Titles (Circular Layout)")
plt.axis("off")  # Hide axes for clarity
plt.show()

# Import the correct module for community detection
from community import community_louvain  # Ensure you have installed `python-louvain`
import matplotlib.pyplot as plt
import seaborn as sns
import networkx as nx

# Community detection to find clusters
partition = community_louvain.best_partition(G)

# Define a color map for clusters
unique_clusters = list(set(partition.values()))
num_clusters = len(unique_clusters)
cluster_palette = sns.color_palette("hsv", num_clusters)
cluster_colors = {genre: cluster_palette[partition[genre]] for genre in G.nodes}

# Set up circular layout with padding for labels
pos = nx.circular_layout(G)

# Create a larger figure with a black background
plt.figure(figsize=(15, 15), facecolor='black')
plt.gca().set_facecolor('black')

# Draw nodes with cluster-based colors
nx.draw_networkx_nodes(G, pos, node_size=node_sizes, node_color=[cluster_colors[node] for node in G], edgecolors="white")

# Draw edges with varying thickness and lighter colors for visibility
edges = nx.draw_networkx_edges(
    G, pos,
    width=[0.05 * G[u][v]['weight'] for u, v in G.edges()],
    alpha=0.5,  # Set transparency for readability
    edge_color=[G[u][v]['weight'] for u, v in G.edges()],
    edge_cmap=plt.cm.coolwarm  # Coolwarm colormap works well on dark backgrounds
)

# Draw labels with white text for visibility
nx.draw_networkx_labels(G, pos, font_size=12, font_color="white", font_family="sans-serif", bbox=dict(facecolor="black", edgecolor='none', boxstyle="round,pad=0.3"))

# Colorbar with adjustments for readability on a black background
colorbar = plt.colorbar(edges, label="Co-occurrence Strength")
colorbar.ax.yaxis.set_tick_params(color='white')
plt.setp(plt.getp(colorbar.ax.axes, 'yticklabels'), color='white')

plt.title("Clustered Genre Co-occurrence Network in Fiction Titles (Circular Layout)", color="white")
plt.axis("off")  # Hide axes for clarity
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns

# Set a style and color palette for cool aesthetics on a black background
plt.style.use('dark_background')
palette = sns.color_palette("Set3", n_colors=18)

# 1. Bar graph of genre frequencies within the dataset we're considering
genre_counts = filtered_fiction_titles[selected_genres].sum()
plt.figure(figsize=(12, 8))
sns.barplot(x=genre_counts.index, y=genre_counts.values, palette=palette)
plt.title("Genre Frequency in Fiction Titles", color="white")
plt.xlabel("Genre", color="white")
plt.ylabel("Frequency", color="white")
plt.xticks(rotation=45, ha='right', color="white")
plt.yticks(color="white")
for i, v in enumerate(genre_counts.values):
    plt.text(i, v + 10, str(v), ha='center', color="white")  # Add frequency labels
plt.show()

# 2. Distribution of the number of genre tags per title
# Calculate the count of genres per title
genre_per_title_count = filtered_fiction_titles[selected_genres].sum(axis=1)
plt.figure(figsize=(10, 6))
sns.histplot(genre_per_title_count, bins=range(1, genre_per_title_count.max() + 2), color="cyan", edgecolor="white")
plt.title("Distribution of Genre Tags per Title", color="white")
plt.xlabel("Number of Genres", color="white")
plt.ylabel("Frequency", color="white")
plt.xticks(color="white")
plt.yticks(color="white")
plt.show()

# 3. Average number of genres associated with each genre type
# Calculate the average number of genres per title for each genre
average_genre_tags = {}
for genre in selected_genres:
    # Filter titles with this genre and calculate average number of genres for them
    titles_with_genre = filtered_fiction_titles[filtered_fiction_titles[genre] == 1]
    average_genre_tags[genre] = titles_with_genre[selected_genres].sum(axis=1).mean()

# Create the bar graph for average number of genres per genre
plt.figure(figsize=(12, 8))
sns.barplot(x=list(average_genre_tags.keys()), y=list(average_genre_tags.values()), palette=palette)
plt.title("Average Number of Genre Tags Attached to Each Genre", color="white")
plt.xlabel("Genre", color="white")
plt.ylabel("Average Number of Genres", color="white")
plt.xticks(rotation=45, ha='right', color="white")
plt.yticks(color="white")
for i, v in enumerate(average_genre_tags.values()):
    plt.text(i, v + 0.1, f"{v:.2f}", ha='center', color="white")  # Add average labels
plt.show()